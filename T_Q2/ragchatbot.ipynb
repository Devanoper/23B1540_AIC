{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Importing dependencies",
   "id": "b290d146742c5c89"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-18T16:36:46.835891Z",
     "start_time": "2024-05-18T16:36:46.445655Z"
    }
   },
   "source": [
    "import os\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.document_loaders import TextLoader\n",
    "from langchain.embeddings import HuggingFaceEmbeddings"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "cutting down the text into smaller chunks because of matrix size restriction in LLMS",
   "id": "25a35074e5c522a5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T16:36:55.074840Z",
     "start_time": "2024-05-18T16:36:46.835891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "os.environ['PINECONE_API_KEY'] = 'ca849d1c-4b47-41d5-a2b1-569bd8f538e9'\n",
    "os.environ['HUGGINGFACE_API_KEY'] = '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'\n",
    "loader = TextLoader(\"ugrulebook.txt\", encoding = 'UTF-8')\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=4)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings()"
   ],
   "id": "828c4de9c5f8aeb5",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devan\\PycharmProjects\\ragbot\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "C:\\Users\\devan\\PycharmProjects\\ragbot\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Creating vector database from txt file",
   "id": "7326cfe7c8c64aea"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T16:37:55.650017Z",
     "start_time": "2024-05-18T16:37:48.847980Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "import pinecone\n",
    "\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "pc = Pinecone(\n",
    "        api_key=os.environ.get(\"PINECONE_API_KEY\")\n",
    "    )\n",
    "\n",
    "# Define Index Name\n",
    "index_name = \"myindex3\"\n",
    "\n",
    "# Checking Index\n",
    "if 'myindex3' not in pc.list_indexes().names():\n",
    "    docsearch= pc.create_index(\n",
    "        name='myindex3', \n",
    "            dimension=1536, \n",
    "            metric='euclidean',\n",
    "            spec=ServerlessSpec(\n",
    "                cloud='aws',\n",
    "                region='us-east-1'\n",
    "            )\n",
    "        )\n",
    "    docsearch = PineconeVectorStore.from_documents(docs, embedding=embeddings, index_name=index_name)\n",
    "\n",
    "else:\n",
    "  # Link to the existing index\n",
    "  docsearch = PineconeVectorStore.from_documents(docs, embedding=embeddings, index_name=index_name)"
   ],
   "id": "bf287d7d45cae409",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "importing a pre-trained LLM",
   "id": "9016672a8f60bd34"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T16:38:04.454683Z",
     "start_time": "2024-05-18T16:38:04.043237Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.llms import HuggingFaceHub\n",
    "\n",
    "# Define the repo ID and connect to Mixtral model on Huggingface\n",
    "repo_id = \"mistralai/Mixtral-8x7B-Instruct-v0.1\"\n",
    "llm = HuggingFaceHub(\n",
    "  repo_id=repo_id, \n",
    "  model_kwargs={\"temperature\": 0.8, \"top_k\": 50}, \n",
    "  huggingfacehub_api_token=os.getenv('HUGGINGFACE_API_KEY')\n",
    ")"
   ],
   "id": "6061cd9cbec23a49",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devan\\PycharmProjects\\ragbot\\.venv\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The class `HuggingFaceHub` was deprecated in LangChain 0.0.21 and will be removed in 0.3.0. Use HuggingFaceEndpoint instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Setting up promp template",
   "id": "1d1d0814d8027f05"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T16:38:08.680725Z",
     "start_time": "2024-05-18T16:38:08.571661Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "You are an academic councillor . The user will ask you queries about academic infrastructure or academic policies. Answer in a formal way and keep it precise\n",
    "\n",
    "Context: {context}\n",
    "Question: {question}\n",
    "Answer: \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "  template=template, \n",
    "  input_variables=[\"context\", \"question\"]\n",
    ")"
   ],
   "id": "780f96fe2612d861",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "creating chain for the exchange b/w user and bot including the context through the txt file",
   "id": "322462a770ba8c27"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T16:38:10.352287Z",
     "start_time": "2024-05-18T16:38:10.331904Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "rag_chain = (\n",
    "  {\"context\": docsearch.as_retriever(),  \"question\": RunnablePassthrough()} \n",
    "  | prompt \n",
    "  | llm\n",
    "  | StrOutputParser() \n",
    ")"
   ],
   "id": "ce3d1fa5a6df0ee0",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-18T16:38:56.970594Z",
     "start_time": "2024-05-18T16:38:56.955933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rag_chain = (\n",
    "    {\"context\": docsearch.as_retriever(),  \"question\": RunnablePassthrough()} \n",
    "    | prompt \n",
    "    | llm\n",
    "    | StrOutputParser() \n",
    "  )"
   ],
   "id": "6f505841056dc76b",
   "outputs": [],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
